{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooihaw/ml_dl_comparison/blob/main/ml_shape_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em7pXGsZepMJ"
      },
      "source": [
        "### Shape classification using machine learning\n",
        "In this hands-on, we will go through the machine learning workflow of data preparation, training, testing, tuning and deployment of a  model for the classification of circles, squares and triangles."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!cd /content/\n",
        "!gdown 1Hr3CAZPjFUkrLGmA070BMS7J6UL7YWi_ -O three_shapes_filled.zip\n",
        "!unzip /content/three_shapes_filled.zip > /dev/null && echo \"A total of $(find /content/three_shapes_filled/ -type f | wc -l) files have been successfully extracted.\""
      ],
      "metadata": {
        "id": "nDAJyfXofBm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-IEfFxjepML"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "%matplotlib inline\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XyaMT17ZepMN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from random import randrange\n",
        "\n",
        "filelist = []\n",
        "labels = []\n",
        "for root, dirs, files in os.walk('three_shapes_filled/'):\n",
        "    print(f'Folder: {root}, sub-folders: {dirs}, number of files: {len(files)}')\n",
        "    if len(files) == 0:\n",
        "        continue\n",
        "    filelist.extend([os.path.join(root, f) for f in files])\n",
        "    dir = root.split('/')[-1]\n",
        "    labels.extend([dir] * len(files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjOPfk-jepMN"
      },
      "outputs": [],
      "source": [
        "# Read image and reshape as 1D array\n",
        "images = imread(filelist[0], as_gray=True).reshape(1, -1)\n",
        "for i in range(1, len(filelist)):\n",
        "    images = np.append(images, imread(filelist[i], as_gray=True).reshape(1, -1), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AMEBIk7epMN"
      },
      "outputs": [],
      "source": [
        "X = images\n",
        "y = np.array(labels)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R1YcZe_epMO"
      },
      "outputs": [],
      "source": [
        "indices = [randrange(len(X)) for i in range(15)]\n",
        "fig, axes = plt.subplots(3, 5)\n",
        "for ax, image, label in zip(axes.ravel(), X[indices], y[indices]):\n",
        "    ax.set_axis_off()\n",
        "    ax.set_title(label)\n",
        "    ax.imshow(image.reshape(32, 32), cmap='gray', interpolation='nearest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQiC2ZNcepMO"
      },
      "source": [
        "- To do:\n",
        "  - Split the dataset into training and testing sets.\n",
        "  - Train a knn model (using default settings).\n",
        "  - Evaluate its performance using the testing set and print the score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkvSNToeepMO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split as split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPFZ_cxFepMP"
      },
      "source": [
        "- To do:\n",
        "  - Construct a pipeline with three steps: scaling ('scl'), dimensionality reduction using PCA ('dr') and classification ('clf').\n",
        "  - Use gridsearch to search for the best process for each steps as follows:\n",
        "    - scaling: No scaling, MinMaxScaler, StandardScaler.\n",
        "    - dimensionality reduction with PCA: test with 50 to 150 principal components (with an interval of 10).\n",
        "    - classification: test with kNN, logistic regression, decision tree, random forests, gradient boosted tree, extreme gradient boost, support vector machine and multilayer perceptron on this dataset with no rescaling, MinMaxScaler, StandardScaler and RobustScaler.\n",
        "    - Use default settings for all the classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHXtW_2tepMP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2CsU7_hepMP"
      },
      "source": [
        "-  To do:\n",
        "  - Store the best model as 'model'.\n",
        "  - Evaluate the best model using the testing set and print the score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHuFkItGepMQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR72wrHnepMQ"
      },
      "source": [
        "- Random select 15 test data and predict their corresponding classes.\n",
        "- Plot the test data and the predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wR8xxm4epMQ"
      },
      "outputs": [],
      "source": [
        "ind_test = [randrange(len(X_test)) for i in range(15)]\n",
        "y_pred = model.predict(X_test[ind_test])\n",
        "\n",
        "fig, axes = plt.subplots(3, 5)\n",
        "for ax, image, label in zip(axes.ravel(), X_test[ind_test], y_pred):\n",
        "    ax.set_axis_off()\n",
        "    ax.set_title(label)\n",
        "    ax.imshow(image.reshape(32, 32), cmap='gray', interpolation='nearest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl55SKrdepMQ"
      },
      "source": [
        "To do:  \n",
        "- Print classification report\n",
        "- Plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6QJjA-ADepMQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}